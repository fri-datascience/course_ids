<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Web scraping | Introduction to data science</title>
  <meta name="description" content="Course notes" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Web scraping | Introduction to data science" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://fri-datascience.github.io/course_itds/" />
  
  <meta property="og:description" content="Course notes" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Web scraping | Introduction to data science" />
  
  <meta name="twitter:description" content="Course notes" />
  

<meta name="author" content="Slavko Žitnik and Erik Štrumbelj" />


<meta name="date" content="2021-01-26" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="reproducibility.html"/>
<link rel="next" href="summarizing-data-basics.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to data science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="what-is-data-science-anyway.html"><a href="what-is-data-science-anyway.html"><i class="fa fa-check"></i>What is data science anyway?</a><ul>
<li class="chapter" data-level="0.1" data-path="what-is-data-science-anyway.html"><a href="what-is-data-science-anyway.html#the-role-of-this-course"><i class="fa fa-check"></i><b>0.1</b> The role of this course</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="python-introduction-chapter.html"><a href="python-introduction-chapter.html"><i class="fa fa-check"></i><b>1</b> Python programming language</a><ul>
<li class="chapter" data-level="1.1" data-path="python-introduction-chapter.html"><a href="python-introduction-chapter.html#basic-characteristics"><i class="fa fa-check"></i><b>1.1</b> Basic characteristics</a></li>
<li class="chapter" data-level="1.2" data-path="python-introduction-chapter.html"><a href="python-introduction-chapter.html#why-python"><i class="fa fa-check"></i><b>1.2</b> Why Python?</a></li>
<li class="chapter" data-level="1.3" data-path="python-introduction-chapter.html"><a href="python-introduction-chapter.html#setting-up-the-environment"><i class="fa fa-check"></i><b>1.3</b> Setting up the environment</a><ul>
<li class="chapter" data-level="1.3.1" data-path="python-introduction-chapter.html"><a href="python-introduction-chapter.html#anaconda-distribution-installation"><i class="fa fa-check"></i><b>1.3.1</b> Anaconda distribution installation</a></li>
<li class="chapter" data-level="1.3.2" data-path="python-introduction-chapter.html"><a href="python-introduction-chapter.html#pure-python-distribution-installation"><i class="fa fa-check"></i><b>1.3.2</b> Pure Python distribution installation</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="python-introduction-chapter.html"><a href="python-introduction-chapter.html#installing-dependencies"><i class="fa fa-check"></i><b>1.4</b> Installing dependencies</a></li>
<li class="chapter" data-level="1.5" data-path="python-introduction-chapter.html"><a href="python-introduction-chapter.html#jupyter-notebooks"><i class="fa fa-check"></i><b>1.5</b> Jupyter notebooks</a><ul>
<li class="chapter" data-level="1.5.1" data-path="python-introduction-chapter.html"><a href="python-introduction-chapter.html#running-a-jupyter-notebook"><i class="fa fa-check"></i><b>1.5.1</b> Running a Jupyter notebook</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="python-introduction-chapter.html"><a href="python-introduction-chapter.html#a-short-introduction-to-python"><i class="fa fa-check"></i><b>1.6</b> A short introduction to Python</a><ul>
<li class="chapter" data-level="" data-path="python-introduction-chapter.html"><a href="python-introduction-chapter.html#basics"><i class="fa fa-check"></i>Basics</a></li>
<li class="chapter" data-level="1.6.1" data-path="python-introduction-chapter.html"><a href="python-introduction-chapter.html#flow-control"><i class="fa fa-check"></i><b>1.6.1</b> Flow control</a></li>
<li class="chapter" data-level="1.6.2" data-path="python-introduction-chapter.html"><a href="python-introduction-chapter.html#functions"><i class="fa fa-check"></i><b>1.6.2</b> Functions</a></li>
<li class="chapter" data-level="1.6.3" data-path="python-introduction-chapter.html"><a href="python-introduction-chapter.html#classes-and-objects"><i class="fa fa-check"></i><b>1.6.3</b> Classes and objects</a></li>
<li class="chapter" data-level="1.6.4" data-path="python-introduction-chapter.html"><a href="python-introduction-chapter.html#reading-and-writing-files"><i class="fa fa-check"></i><b>1.6.4</b> Reading and writing files</a></li>
<li class="chapter" data-level="1.6.5" data-path="python-introduction-chapter.html"><a href="python-introduction-chapter.html#python-ides-and-code-editors"><i class="fa fa-check"></i><b>1.6.5</b> Python IDE’s and code editors</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="python-introduction-chapter.html"><a href="python-introduction-chapter.html#python-ecosystem-for-data-science"><i class="fa fa-check"></i><b>1.7</b> Python ecosystem for Data Science</a></li>
<li class="chapter" data-level="1.8" data-path="python-introduction-chapter.html"><a href="python-introduction-chapter.html#further-reading-and-references"><i class="fa fa-check"></i><b>1.8</b> Further reading and references</a></li>
<li class="chapter" data-level="1.9" data-path="python-introduction-chapter.html"><a href="python-introduction-chapter.html#learning-outcomes"><i class="fa fa-check"></i><b>1.9</b> Learning outcomes</a></li>
<li class="chapter" data-level="1.10" data-path="python-introduction-chapter.html"><a href="python-introduction-chapter.html#practice-problems"><i class="fa fa-check"></i><b>1.10</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="git.html"><a href="git.html"><i class="fa fa-check"></i><b>2</b> Source code control</a><ul>
<li class="chapter" data-level="2.1" data-path="git.html"><a href="git.html#overview"><i class="fa fa-check"></i><b>2.1</b> Overview</a></li>
<li class="chapter" data-level="2.2" data-path="git.html"><a href="git.html#why-should-i-know-about-git"><i class="fa fa-check"></i><b>2.2</b> Why should I know about Git</a></li>
<li class="chapter" data-level="2.3" data-path="git.html"><a href="git.html#basic-git-terminology"><i class="fa fa-check"></i><b>2.3</b> Basic Git terminology</a><ul>
<li class="chapter" data-level="2.3.1" data-path="git.html"><a href="git.html#repository"><i class="fa fa-check"></i><b>2.3.1</b> Repository</a></li>
<li class="chapter" data-level="2.3.2" data-path="git.html"><a href="git.html#clone"><i class="fa fa-check"></i><b>2.3.2</b> Clone</a></li>
<li class="chapter" data-level="2.3.3" data-path="git.html"><a href="git.html#adding"><i class="fa fa-check"></i><b>2.3.3</b> Adding</a></li>
<li class="chapter" data-level="2.3.4" data-path="git.html"><a href="git.html#commit"><i class="fa fa-check"></i><b>2.3.4</b> Commit</a></li>
<li class="chapter" data-level="2.3.5" data-path="git.html"><a href="git.html#push"><i class="fa fa-check"></i><b>2.3.5</b> Push</a></li>
<li class="chapter" data-level="2.3.6" data-path="git.html"><a href="git.html#pull"><i class="fa fa-check"></i><b>2.3.6</b> Pull</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="git.html"><a href="git.html#a-beginner-git-example"><i class="fa fa-check"></i><b>2.4</b> A beginner Git example</a></li>
<li class="chapter" data-level="2.5" data-path="git.html"><a href="git.html#beyond-the-basics"><i class="fa fa-check"></i><b>2.5</b> Beyond the basics</a><ul>
<li class="chapter" data-level="2.5.1" data-path="git.html"><a href="git.html#conflict-resolution"><i class="fa fa-check"></i><b>2.5.1</b> Conflict resolution</a></li>
<li class="chapter" data-level="2.5.2" data-path="git.html"><a href="git.html#git-branching"><i class="fa fa-check"></i><b>2.5.2</b> Branching</a></li>
<li class="chapter" data-level="2.5.3" data-path="git.html"><a href="git.html#forking"><i class="fa fa-check"></i><b>2.5.3</b> Forking</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="git.html"><a href="git.html#git-guis"><i class="fa fa-check"></i><b>2.6</b> Git tools</a></li>
<li class="chapter" data-level="2.7" data-path="git.html"><a href="git.html#further-reading-and-references-1"><i class="fa fa-check"></i><b>2.7</b> Further reading and references</a></li>
<li class="chapter" data-level="2.8" data-path="git.html"><a href="git.html#learning-outcomes-1"><i class="fa fa-check"></i><b>2.8</b> Learning outcomes</a></li>
<li class="chapter" data-level="2.9" data-path="git.html"><a href="git.html#practice-problems-1"><i class="fa fa-check"></i><b>2.9</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="reproducibility.html"><a href="reproducibility.html"><i class="fa fa-check"></i><b>3</b> Reproducible research</a><ul>
<li class="chapter" data-level="3.1" data-path="reproducibility.html"><a href="reproducibility.html#scientific-inquiry"><i class="fa fa-check"></i><b>3.1</b> Scientific inquiry</a></li>
<li class="chapter" data-level="3.2" data-path="reproducibility.html"><a href="reproducibility.html#from-principles-to-practice"><i class="fa fa-check"></i><b>3.2</b> From principles to practice</a><ul>
<li class="chapter" data-level="3.2.1" data-path="reproducibility.html"><a href="reproducibility.html#preregistration---the-future-standard"><i class="fa fa-check"></i><b>3.2.1</b> Preregistration - the future standard</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="reproducibility.html"><a href="reproducibility.html#reproducibility-tools-in-r"><i class="fa fa-check"></i><b>3.3</b> Reproducibility tools in R</a><ul>
<li class="chapter" data-level="" data-path="reproducibility.html"><a href="reproducibility.html#r-markdown"><i class="fa fa-check"></i>R Markdown</a></li>
<li class="chapter" data-level="" data-path="reproducibility.html"><a href="reproducibility.html#r-notebook"><i class="fa fa-check"></i>R Notebook</a></li>
<li class="chapter" data-level="" data-path="reproducibility.html"><a href="reproducibility.html#sweave"><i class="fa fa-check"></i>Sweave</a></li>
<li class="chapter" data-level="" data-path="reproducibility.html"><a href="reproducibility.html#shiny-web-apps-and-dashboards"><i class="fa fa-check"></i>Shiny web apps and dashboards</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="reproducibility.html"><a href="reproducibility.html#reproducibility-tools-in-python"><i class="fa fa-check"></i><b>3.4</b> Reproducibility tools in Python</a><ul>
<li class="chapter" data-level="" data-path="reproducibility.html"><a href="reproducibility.html#jupyter-dashboards"><i class="fa fa-check"></i>Jupyter Dashboards</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="reproducibility.html"><a href="reproducibility.html#data-dashboards---tooling-and-libraries"><i class="fa fa-check"></i><b>3.5</b> Data dashboards - tooling and libraries</a></li>
<li class="chapter" data-level="3.6" data-path="reproducibility.html"><a href="reproducibility.html#further-reading-and-references-2"><i class="fa fa-check"></i><b>3.6</b> Further reading and references</a></li>
<li class="chapter" data-level="3.7" data-path="reproducibility.html"><a href="reproducibility.html#learning-outcomes-2"><i class="fa fa-check"></i><b>3.7</b> Learning outcomes</a></li>
<li class="chapter" data-level="3.8" data-path="reproducibility.html"><a href="reproducibility.html#practice-problems-2"><i class="fa fa-check"></i><b>3.8</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="scraping.html"><a href="scraping.html"><i class="fa fa-check"></i><b>4</b> Web scraping</a><ul>
<li class="chapter" data-level="4.1" data-path="scraping.html"><a href="scraping.html#introduction-to-web-data-extraction"><i class="fa fa-check"></i><b>4.1</b> Introduction to Web data extraction</a><ul>
<li class="chapter" data-level="" data-path="scraping.html"><a href="scraping.html#the-challenges-of-web-data-extraction"><i class="fa fa-check"></i>The challenges of Web data extraction</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="scraping.html"><a href="scraping.html#web-wrapper"><i class="fa fa-check"></i><b>4.2</b> Web wrapper</a><ul>
<li class="chapter" data-level="4.2.1" data-path="scraping.html"><a href="scraping.html#html-dom"><i class="fa fa-check"></i><b>4.2.1</b> HTML DOM</a></li>
<li class="chapter" data-level="4.2.2" data-path="scraping.html"><a href="scraping.html#xpath"><i class="fa fa-check"></i><b>4.2.2</b> XPath</a></li>
<li class="chapter" data-level="4.2.3" data-path="scraping.html"><a href="scraping.html#modern-web-sites-and-js-frameworks"><i class="fa fa-check"></i><b>4.2.3</b> Modern Web sites and JS frameworks</a></li>
<li class="chapter" data-level="4.2.4" data-path="scraping.html"><a href="scraping.html#crawling-resources-and-policies"><i class="fa fa-check"></i><b>4.2.4</b> Crawling, resources and policies</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="scraping.html"><a href="scraping.html#further-reading-and-references-3"><i class="fa fa-check"></i><b>4.3</b> Further reading and references</a></li>
<li class="chapter" data-level="4.4" data-path="scraping.html"><a href="scraping.html#learning-outcomes-3"><i class="fa fa-check"></i><b>4.4</b> Learning outcomes</a></li>
<li class="chapter" data-level="4.5" data-path="scraping.html"><a href="scraping.html#practice-problems-3"><i class="fa fa-check"></i><b>4.5</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="summarizing-data-basics.html"><a href="summarizing-data-basics.html"><i class="fa fa-check"></i><b>5</b> Summarizing data - the basics</a><ul>
<li class="chapter" data-level="5.1" data-path="summarizing-data-basics.html"><a href="summarizing-data-basics.html#descriptive-statistics-for-univariate-distributions"><i class="fa fa-check"></i><b>5.1</b> Descriptive statistics for univariate distributions</a><ul>
<li class="chapter" data-level="5.1.1" data-path="summarizing-data-basics.html"><a href="summarizing-data-basics.html#central-tendency"><i class="fa fa-check"></i><b>5.1.1</b> Central tendency</a></li>
<li class="chapter" data-level="5.1.2" data-path="summarizing-data-basics.html"><a href="summarizing-data-basics.html#dispersion"><i class="fa fa-check"></i><b>5.1.2</b> Dispersion</a></li>
<li class="chapter" data-level="5.1.3" data-path="summarizing-data-basics.html"><a href="summarizing-data-basics.html#skewness-and-kurtosis"><i class="fa fa-check"></i><b>5.1.3</b> Skewness and kurtosis</a></li>
<li class="chapter" data-level="5.1.4" data-path="summarizing-data-basics.html"><a href="summarizing-data-basics.html#nominal-variables"><i class="fa fa-check"></i><b>5.1.4</b> Nominal variables</a></li>
<li class="chapter" data-level="5.1.5" data-path="summarizing-data-basics.html"><a href="summarizing-data-basics.html#testing-the-shape-of-a-distribution"><i class="fa fa-check"></i><b>5.1.5</b> Testing the shape of a distribution</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="summarizing-data-basics.html"><a href="summarizing-data-basics.html#descriptive-statistics-for-bivariate-distributions"><i class="fa fa-check"></i><b>5.2</b> Descriptive statistics for bivariate distributions</a></li>
<li class="chapter" data-level="5.3" data-path="summarizing-data-basics.html"><a href="summarizing-data-basics.html#further-reading-and-references-4"><i class="fa fa-check"></i><b>5.3</b> Further reading and references</a></li>
<li class="chapter" data-level="5.4" data-path="summarizing-data-basics.html"><a href="summarizing-data-basics.html#learning-outcomes-4"><i class="fa fa-check"></i><b>5.4</b> Learning outcomes</a></li>
<li class="chapter" data-level="5.5" data-path="summarizing-data-basics.html"><a href="summarizing-data-basics.html#practice-problems-4"><i class="fa fa-check"></i><b>5.5</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="docker.html"><a href="docker.html"><i class="fa fa-check"></i><b>6</b> Docker container platform</a><ul>
<li class="chapter" data-level="6.1" data-path="docker.html"><a href="docker.html#why-docker"><i class="fa fa-check"></i><b>6.1</b> Why Docker?</a></li>
<li class="chapter" data-level="6.2" data-path="docker.html"><a href="docker.html#setting-up-the-environment-1"><i class="fa fa-check"></i><b>6.2</b> Setting up the environment</a></li>
<li class="chapter" data-level="6.3" data-path="docker.html"><a href="docker.html#short-introduction-to-docker"><i class="fa fa-check"></i><b>6.3</b> Short introduction to Docker</a><ul>
<li class="chapter" data-level="6.3.1" data-path="docker.html"><a href="docker.html#basics-1"><i class="fa fa-check"></i><b>6.3.1</b> Basics</a></li>
<li class="chapter" data-level="6.3.2" data-path="docker.html"><a href="docker.html#docker-application-example"><i class="fa fa-check"></i><b>6.3.2</b> Docker application example</a></li>
<li class="chapter" data-level="6.3.3" data-path="docker.html"><a href="docker.html#volumes"><i class="fa fa-check"></i><b>6.3.3</b> Volumes</a></li>
<li class="chapter" data-level="6.3.4" data-path="docker.html"><a href="docker.html#docker-application-example-with-multiple-services"><i class="fa fa-check"></i><b>6.3.4</b> Docker application example with multiple services</a></li>
<li class="chapter" data-level="6.3.5" data-path="docker.html"><a href="docker.html#dockerfile-optimizations"><i class="fa fa-check"></i><b>6.3.5</b> Dockerfile optimizations</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="docker.html"><a href="docker.html#further-reading-and-references-5"><i class="fa fa-check"></i><b>6.4</b> Further reading and references</a></li>
<li class="chapter" data-level="6.5" data-path="docker.html"><a href="docker.html#learning-outcomes-5"><i class="fa fa-check"></i><b>6.5</b> Learning outcomes</a></li>
<li class="chapter" data-level="6.6" data-path="docker.html"><a href="docker.html#practice-problems-5"><i class="fa fa-check"></i><b>6.6</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="summarize2.html"><a href="summarize2.html"><i class="fa fa-check"></i><b>7</b> Summarizing data - visualization</a><ul>
<li class="chapter" data-level="7.1" data-path="summarize2.html"><a href="summarize2.html#histograms-and-density-plots"><i class="fa fa-check"></i><b>7.1</b> Histograms and density plots</a></li>
<li class="chapter" data-level="7.2" data-path="summarize2.html"><a href="summarize2.html#bar-plot"><i class="fa fa-check"></i><b>7.2</b> Bar plot</a></li>
<li class="chapter" data-level="7.3" data-path="summarize2.html"><a href="summarize2.html#pie-chart"><i class="fa fa-check"></i><b>7.3</b> Pie chart</a></li>
<li class="chapter" data-level="7.4" data-path="summarize2.html"><a href="summarize2.html#scatterplot"><i class="fa fa-check"></i><b>7.4</b> Scatterplot</a></li>
<li class="chapter" data-level="7.5" data-path="summarize2.html"><a href="summarize2.html#d-density-plot"><i class="fa fa-check"></i><b>7.5</b> 2D density plot</a></li>
<li class="chapter" data-level="7.6" data-path="summarize2.html"><a href="summarize2.html#boxplot"><i class="fa fa-check"></i><b>7.6</b> Boxplot</a></li>
<li class="chapter" data-level="7.7" data-path="summarize2.html"><a href="summarize2.html#violin-plot"><i class="fa fa-check"></i><b>7.7</b> Violin plot</a></li>
<li class="chapter" data-level="7.8" data-path="summarize2.html"><a href="summarize2.html#correlogram"><i class="fa fa-check"></i><b>7.8</b> Correlogram</a></li>
<li class="chapter" data-level="7.9" data-path="summarize2.html"><a href="summarize2.html#a-comprehensive-summary"><i class="fa fa-check"></i><b>7.9</b> A comprehensive summary</a></li>
<li class="chapter" data-level="7.10" data-path="summarize2.html"><a href="summarize2.html#further-reading-and-references-6"><i class="fa fa-check"></i><b>7.10</b> Further reading and references</a></li>
<li class="chapter" data-level="7.11" data-path="summarize2.html"><a href="summarize2.html#learning-outcomes-6"><i class="fa fa-check"></i><b>7.11</b> Learning outcomes</a></li>
<li class="chapter" data-level="7.12" data-path="summarize2.html"><a href="summarize2.html#practice-problems-6"><i class="fa fa-check"></i><b>7.12</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="multivariate-data-chapter.html"><a href="multivariate-data-chapter.html"><i class="fa fa-check"></i><b>8</b> Summarizing data - multivariate data</a><ul>
<li class="chapter" data-level="8.1" data-path="multivariate-data-chapter.html"><a href="multivariate-data-chapter.html#principal-component-analysis-pca"><i class="fa fa-check"></i><b>8.1</b> Principal Component Analysis (PCA)</a></li>
<li class="chapter" data-level="8.2" data-path="multivariate-data-chapter.html"><a href="multivariate-data-chapter.html#factor-analysis-fa"><i class="fa fa-check"></i><b>8.2</b> Factor analysis (FA)</a></li>
<li class="chapter" data-level="8.3" data-path="multivariate-data-chapter.html"><a href="multivariate-data-chapter.html#multi-dimensional-scaling-mds"><i class="fa fa-check"></i><b>8.3</b> Multi-dimensional scaling (MDS)</a></li>
<li class="chapter" data-level="8.4" data-path="multivariate-data-chapter.html"><a href="multivariate-data-chapter.html#t-distributed-stochastic-neighbor-embedding-t-sne"><i class="fa fa-check"></i><b>8.4</b> t-Distributed Stochastic Neighbor Embedding (t-SNE)</a></li>
<li class="chapter" data-level="8.5" data-path="multivariate-data-chapter.html"><a href="multivariate-data-chapter.html#clustering"><i class="fa fa-check"></i><b>8.5</b> Clustering</a><ul>
<li class="chapter" data-level="8.5.1" data-path="multivariate-data-chapter.html"><a href="multivariate-data-chapter.html#k-means-clustering"><i class="fa fa-check"></i><b>8.5.1</b> k-means clustering</a></li>
<li class="chapter" data-level="8.5.2" data-path="multivariate-data-chapter.html"><a href="multivariate-data-chapter.html#determining-the-number-of-clusters"><i class="fa fa-check"></i><b>8.5.2</b> Determining the number of clusters</a></li>
<li class="chapter" data-level="8.5.3" data-path="multivariate-data-chapter.html"><a href="multivariate-data-chapter.html#agglomerative-hierarchical-clustering"><i class="fa fa-check"></i><b>8.5.3</b> Agglomerative hierarchical clustering</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="multivariate-data-chapter.html"><a href="multivariate-data-chapter.html#further-reading-and-references-7"><i class="fa fa-check"></i><b>8.6</b> Further reading and references</a></li>
<li class="chapter" data-level="8.7" data-path="multivariate-data-chapter.html"><a href="multivariate-data-chapter.html#learning-outcomes-7"><i class="fa fa-check"></i><b>8.7</b> Learning outcomes</a></li>
<li class="chapter" data-level="8.8" data-path="multivariate-data-chapter.html"><a href="multivariate-data-chapter.html#practice-problems-7"><i class="fa fa-check"></i><b>8.8</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="databases.html"><a href="databases.html"><i class="fa fa-check"></i><b>9</b> Relational databases</a><ul>
<li class="chapter" data-level="9.1" data-path="databases.html"><a href="databases.html#introduction-to-sql"><i class="fa fa-check"></i><b>9.1</b> Introduction to SQL</a><ul>
<li class="chapter" data-level="9.1.1" data-path="databases.html"><a href="databases.html#data-definition-language"><i class="fa fa-check"></i><b>9.1.1</b> Data definition language</a></li>
<li class="chapter" data-level="9.1.2" data-path="databases.html"><a href="databases.html#data-manipulation-language"><i class="fa fa-check"></i><b>9.1.2</b> Data manipulation language</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="databases.html"><a href="databases.html#sqlite"><i class="fa fa-check"></i><b>9.2</b> SQLite</a><ul>
<li class="chapter" data-level="9.2.1" data-path="databases.html"><a href="databases.html#environment-setup"><i class="fa fa-check"></i><b>9.2.1</b> Environment setup</a></li>
<li class="chapter" data-level="9.2.2" data-path="databases.html"><a href="databases.html#sqlite-example"><i class="fa fa-check"></i><b>9.2.2</b> SQLite database usage</a></li>
<li class="chapter" data-level="9.2.3" data-path="databases.html"><a href="databases.html#sqlite-in-python"><i class="fa fa-check"></i><b>9.2.3</b> SQLite in Python</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="databases.html"><a href="databases.html#postgresql"><i class="fa fa-check"></i><b>9.3</b> PostgreSQL</a></li>
<li class="chapter" data-level="9.4" data-path="databases.html"><a href="databases.html#further-reading-and-references-8"><i class="fa fa-check"></i><b>9.4</b> Further reading and references</a></li>
<li class="chapter" data-level="9.5" data-path="databases.html"><a href="databases.html#learning-outcomes-8"><i class="fa fa-check"></i><b>9.5</b> Learning outcomes</a></li>
<li class="chapter" data-level="9.6" data-path="databases.html"><a href="databases.html#practice-problems-8"><i class="fa fa-check"></i><b>9.6</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="predictive.html"><a href="predictive.html"><i class="fa fa-check"></i><b>10</b> Predictive modelling</a><ul>
<li class="chapter" data-level="10.1" data-path="predictive.html"><a href="predictive.html#introduction"><i class="fa fa-check"></i><b>10.1</b> Introduction</a><ul>
<li class="chapter" data-level="" data-path="predictive.html"><a href="predictive.html#key-terms"><i class="fa fa-check"></i>Key terms</a></li>
<li class="chapter" data-level="" data-path="predictive.html"><a href="predictive.html#an-illustrative-example"><i class="fa fa-check"></i>An illustrative example</a></li>
<li class="chapter" data-level="10.1.1" data-path="predictive.html"><a href="predictive.html#the-process-of-predictive-modelling"><i class="fa fa-check"></i><b>10.1.1</b> The process of predictive modelling</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="predictive.html"><a href="predictive.html#commonly-used-prediction-models-and-paradigms"><i class="fa fa-check"></i><b>10.2</b> Commonly used prediction models and paradigms</a><ul>
<li class="chapter" data-level="" data-path="predictive.html"><a href="predictive.html#generalized-linear-models"><i class="fa fa-check"></i>Generalized linear models</a></li>
<li class="chapter" data-level="" data-path="predictive.html"><a href="predictive.html#decision-trees"><i class="fa fa-check"></i>Decision trees</a></li>
<li class="chapter" data-level="" data-path="predictive.html"><a href="predictive.html#neural-networks"><i class="fa fa-check"></i>Neural networks</a></li>
<li class="chapter" data-level="" data-path="predictive.html"><a href="predictive.html#kernel-based-learning"><i class="fa fa-check"></i>Kernel-based learning</a></li>
<li class="chapter" data-level="" data-path="predictive.html"><a href="predictive.html#ensemble-learning"><i class="fa fa-check"></i>Ensemble learning</a></li>
<li class="chapter" data-level="" data-path="predictive.html"><a href="predictive.html#common-predictive-modelling-paradigms"><i class="fa fa-check"></i>Common predictive modelling paradigms</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="predictive.html"><a href="predictive.html#model-selection"><i class="fa fa-check"></i><b>10.3</b> Model selection</a><ul>
<li class="chapter" data-level="" data-path="predictive.html"><a href="predictive.html#measuring-predictive-performance"><i class="fa fa-check"></i>Measuring predictive performance</a></li>
<li class="chapter" data-level="" data-path="predictive.html"><a href="predictive.html#estimating-how-performance-will-generalize"><i class="fa fa-check"></i>Estimating how performance will generalize</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="predictive.html"><a href="predictive.html#practical-considerations"><i class="fa fa-check"></i><b>10.4</b> Practical considerations</a></li>
<li class="chapter" data-level="10.5" data-path="predictive.html"><a href="predictive.html#putting-it-all-together-with-r"><i class="fa fa-check"></i><b>10.5</b> Putting it all together with R</a></li>
<li class="chapter" data-level="10.6" data-path="predictive.html"><a href="predictive.html#putting-it-all-together-with-python"><i class="fa fa-check"></i><b>10.6</b> Putting it all together with Python</a></li>
<li class="chapter" data-level="10.7" data-path="predictive.html"><a href="predictive.html#further-reading-and-references-9"><i class="fa fa-check"></i><b>10.7</b> Further reading and references</a></li>
<li class="chapter" data-level="10.8" data-path="predictive.html"><a href="predictive.html#learning-outcomes-9"><i class="fa fa-check"></i><b>10.8</b> Learning outcomes</a></li>
<li class="chapter" data-level="10.9" data-path="predictive.html"><a href="predictive.html#practice-problems-9"><i class="fa fa-check"></i><b>10.9</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="missing-data.html"><a href="missing-data.html"><i class="fa fa-check"></i><b>11</b> Dealing with missing data</a><ul>
<li class="chapter" data-level="11.1" data-path="missing-data.html"><a href="missing-data.html#the-severity-of-the-missing-data-problem"><i class="fa fa-check"></i><b>11.1</b> The severity of the missing data problem</a><ul>
<li class="chapter" data-level="" data-path="missing-data.html"><a href="missing-data.html#three-classes-of-missingness"><i class="fa fa-check"></i>Three classes of missingness</a></li>
<li class="chapter" data-level="" data-path="missing-data.html"><a href="missing-data.html#determining-the-missingness-mechanism"><i class="fa fa-check"></i>Determining the missingness mechanism</a></li>
<li class="chapter" data-level="" data-path="missing-data.html"><a href="missing-data.html#causes-for-missing-data"><i class="fa fa-check"></i>Causes for missing data</a></li>
<li class="chapter" data-level="" data-path="missing-data.html"><a href="missing-data.html#introducing-bias"><i class="fa fa-check"></i>Introducing bias</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="missing-data.html"><a href="missing-data.html#visually-exploring-missingness"><i class="fa fa-check"></i><b>11.2</b> Visually exploring missingness</a></li>
<li class="chapter" data-level="11.3" data-path="missing-data.html"><a href="missing-data.html#deletion-methods"><i class="fa fa-check"></i><b>11.3</b> Deletion methods</a><ul>
<li class="chapter" data-level="11.3.1" data-path="missing-data.html"><a href="missing-data.html#column-deletion"><i class="fa fa-check"></i><b>11.3.1</b> Column deletion</a></li>
<li class="chapter" data-level="11.3.2" data-path="missing-data.html"><a href="missing-data.html#row-deletion"><i class="fa fa-check"></i><b>11.3.2</b> Row deletion</a></li>
<li class="chapter" data-level="11.3.3" data-path="missing-data.html"><a href="missing-data.html#pairwise-deletion"><i class="fa fa-check"></i><b>11.3.3</b> Pairwise deletion</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="missing-data.html"><a href="missing-data.html#imputation-methods"><i class="fa fa-check"></i><b>11.4</b> Imputation methods</a><ul>
<li class="chapter" data-level="11.4.1" data-path="missing-data.html"><a href="missing-data.html#single-imputation-with-the-mean"><i class="fa fa-check"></i><b>11.4.1</b> Single imputation with the mean</a></li>
<li class="chapter" data-level="11.4.2" data-path="missing-data.html"><a href="missing-data.html#single-imputation-with-prediction"><i class="fa fa-check"></i><b>11.4.2</b> Single imputation with prediction</a></li>
<li class="chapter" data-level="11.4.3" data-path="missing-data.html"><a href="missing-data.html#multiple-imputation"><i class="fa fa-check"></i><b>11.4.3</b> Multiple imputation</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="missing-data.html"><a href="missing-data.html#summary"><i class="fa fa-check"></i><b>11.5</b> Summary</a></li>
<li class="chapter" data-level="11.6" data-path="missing-data.html"><a href="missing-data.html#further-reading-and-references-10"><i class="fa fa-check"></i><b>11.6</b> Further reading and references</a></li>
<li class="chapter" data-level="11.7" data-path="missing-data.html"><a href="missing-data.html#learning-outcomes-10"><i class="fa fa-check"></i><b>11.7</b> Learning outcomes</a></li>
<li class="chapter" data-level="11.8" data-path="missing-data.html"><a href="missing-data.html#practice-problems-10"><i class="fa fa-check"></i><b>11.8</b> Practice problems</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://datascience.fri.uni-lj.si/" target="blank">Data Science Master's Program</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to data science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="scraping" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Web scraping</h1>
<p>Today there are more than <strong>3.7 billion Internet users</strong>, which almost <strong>50% of the entire population</strong> <span class="citation">(Internet World Stats <a href="#ref-InternetWorldStats" role="doc-biblioref">2017</a>)</span>. Taking into account all the existing Internet-enabled devices, we can estimate that approximatelly 30 billion devices are connected to the internet <span class="citation">(Deitel, Deitel, and Deitel <a href="#ref-deitel2011" role="doc-biblioref">2011</a>)</span>.</p>
<p>In this chapter we focus on Web data extraction (Web scraping) - automatically extracting data from websites and storing it in a structured format. However, the broader field of Web information extraction also requires the knowledge of natural language processing techniques such as text pre-processing, information extraction (entity extraction, relationship extraction, coreference resolution), sentiment analysis, text categorization/classification and language models. Students that are interested in learning more about these techniques are encouraged to enrol in a Natural language processing course. For introduction to natural language techniques please see the Further reading references <span class="citation">(Liu <a href="#ref-liu2011" role="doc-biblioref">2011</a>)</span> (Chapter 11), <span class="citation">(Christopher, Prabhakar, and Hinrich <a href="#ref-manning2008" role="doc-biblioref">2008</a>)</span> (Chapters 12, 13, 15-17, 20), <span class="citation">(Aggarwal and Zhai <a href="#ref-aggarwal2012" role="doc-biblioref">2012</a>)</span> (Chapters 1-8, 12-14) or other specialized books on natural language processing.</p>
<div id="introduction-to-web-data-extraction" class="section level2">
<h2><span class="header-section-number">4.1</span> Introduction to Web data extraction</h2>
<p>Web data extraction systems <span class="citation">(Ferrara et al. <a href="#ref-ferrara2014" role="doc-biblioref">2014</a>)</span> are a broad class of software applications that focus on extracting data from Web sources. A Web data extraction system usually interacts with a Web source and extracts data stored in it: for example, if the source is an HTML Web page, the extracted content could consist of elements in the page as well as the full-text of the page itself. Eventually, extracted data might be post-processed, converted to the most convenient structured format and stored for further usage. The design and implementation of Web data extraction systems has been discussed from different perspectives and it leverages on scientific methods from different disciplines including machine learning, logic and natural language processing.</p>
<p>Web data extraction systems find extensive use in a wide range of applications including the analysis of text-based documents available to a company (like e-mails, support forums, technical and legal documentation, and so on), Business and Competitive Intelligence, crawling of Social Web platforms, Bioinformatics and so on. The importance of Web data extraction systems depends on the fact that a large (and steadily growing) amount of data is continuously produced, shared and consumed online: Web data extraction systems allow us to efficiently collect these data with limited human effort. The availability and analysis of collected data is vital to understanding complex social, scientific and economic phenomena which generate the data. For example, collecting digital traces produced by users of social Web platforms such as Facebook, YouTube or Flickr is the key step to understand, model and predict human behavior.</p>
<p>In commercial fields, the Web provides a wealth of public information. A company can probe the Web to acquire and analyze information about the activity of its competitors. This process is known as Competitive Intelligence and it is crucial to quickly identify the opportunities provided by the market, to anticipate the decisions of the competitors as well as to learn from their faults and successes.</p>
<div id="the-challenges-of-web-data-extraction" class="section level3 unnumbered">
<h3>The challenges of Web data extraction</h3>
<p>In its most general formulation, the problem of extracting data from the Web is very hard because it is constrained by several requirements. The key challenges we can encounter in the design of a Web Data Extraction system can be summarized as follows:</p>
<ul>
<li>Web data extraction techniques implemented in a Web data extraction system often require human input. The first challenge consists of providing a high degree of automation by reducing human efforts as much as possible. Human feedback, however, may play an important role in raising the level of accuracy achieved by a Web data extraction system. A related challenge is to identify a reasonable tradeoff between building highly automated Web data extraction procedures and the requirement of achieving accurate performance.</li>
<li>Web data extraction techniques should be able to process large volumes of data in relatively short time. This requirement is particularly stringent in the field of Business and Competitive Intelligence because a company needs to perform timely analysis of market conditions.</li>
<li>Applications in the field of Social Web or, more in general, those dealing with personal data, must provide solid privacy guarantees. Therefore, potential (even if unintentional) attempts to violate user privacy should be timely and adequately identified and counteracted.</li>
<li>Approaches relying on machine learning often require a large training set of manually labeled Web pages. In general, the task of labeling pages is time comnsuming and error prone and, therefore, in many cases we cannot assume the existence of labeled pages.</li>
<li>Often, a Web data extraction tool has to routinely extract data from a Web Data source which can evolve over time. Web sources are continuously evolving and structural changes happen with no forewarning and are thus unpredictable. In real-world scenarios such systems have to be maintained, because they are likely to eventually stop working correctly, in particular if they lack the flexibility to detect and face structural modifications of the target Web sources.</li>
</ul>
<p>The first attempts to extract data from the Web date back to the early 90s. In the early days, this discipline borrowed approaches and techniques from Information Extraction (IE) literature. In particular, two classes of strategies emerged: <em>learning techniques</em> and <em>knowledge engineering techniques</em> – also called <em>learning-based</em> and <em>rule-based approaches</em>, respectively. These classes share a common rationale: the former was thought to develop systems that require human expertise to define rules (for example, <em>regular expressions</em>) to successfully accomplish the data extraction. These approaches require specific domain expertise: users that design and implement the rules and train the system must have programming experience and a good knowledge of the domain in which the data extraction system will operate; they will also have the ability to envisage potential usage scenarios and tasks assigned to the system. On the other hand, also some approaches of the latter class involve strong familiarity with both the requirements and the functions of the platform, so human input is essential.</p>
</div>
</div>
<div id="web-wrapper" class="section level2">
<h2><span class="header-section-number">4.2</span> Web wrapper</h2>
<p>In the literature, any procedure that aims at extracting structured data from unstructured or semi-structured data sources is usually referred to as a wrapper. In the context of Web data extraction we provide the following definition:</p>
<blockquote>
<p><strong>Web wrapper</strong> is a procedure, that might implement one or many different classes of algorithms, which seeks and finds data required by a human user, extracting them from unstructured (or semi-structured) Web sources, and transforming them into structured data, merging and unifying this information for further processing, in a semi-automated or fully automated way.</p>
</blockquote>
<p>Web wrappers are characterized by a 3-step life-cycle:</p>
<ol style="list-style-type: decimal">
<li><em>Wrapper generation</em>: the wrapper is defined and implemented according to one or more selected techniques.</li>
<li><em>Wrapper execution</em>: the wrapper runs and extracts data continuously.</li>
<li><em>Wrapper maintenance</em>: the structure of data sources may change and the wrapper should be adapted accordingly.</li>
</ol>
<p>The first two steps of a wrapper life-cycle, generation and execution, might be implemented manually, for example, by defining and executing regular expressions over the HTML documents. Alternatively, which is the aim of Web data extraction systems, wrappers might be defined and executed by using an inductive approach – a process commonly known as wrapper induction <span class="citation">(Kushmerick, Weld, and Doorenbos <a href="#ref-kushmerick1997" role="doc-biblioref">1997</a>)</span>. Web wrapper induction is challenging because it requires high-level automation strategies. Induction methods try to uncover structures from an HTML document to form a robust wrapper. There exist also hybrid approaches that make it possible for users to generate and run wrappers semi-automatically by means of visual interfaces.</p>
<p>The third and final step of a wrapper’s life-cycle is maintenance: Web pages change their structure continuously and without forewarning. This might affect the correct functioning of a Web wrapper, whose definition is usually tightly bound to the structure of the Web pages adopted. Defining automated strategies for wrapper maintenance is vital to the correctness of extracted data and the robustness of Web data extraction platforms. Wrapper maintenance is especially important for long-term extractions. For the purposes of acquiring data in a typical data-science project, wrappers are mostly run once or over a short period of time. In such cases it is less likely that a Web site would change, so automation is not a priority and is typicaly not implemented.</p>
<div id="html-dom" class="section level3">
<h3><span class="header-section-number">4.2.1</span> HTML DOM</h3>
<p>HTML is the predominant language for implementing Web pages and it is largely supported by the World Wide Web consortium. HTML pages can be regarded as a form of semi-structured data (even if less structured than other sources like XML documents) in which information follows a nested structure. HTML structure can be exploided in the design of suitable wrappers. While semi-structured information is often also available in non-HTML formats (for example, e-mail messages, code, system logs), extracting information of this type is the subject of more general information extraction and not the focus of this chapter.</p>
<p>The backbone of a Web page is a Hypertext Markup Language (HTML) document which consists of HTML tags. According to the <a href="http://www.w3.org/DOM">Document Object Model</a> (DOM), every HTML tag is an object. Nested tags are called children of the enclosing tag. Generally we first parse a web page into a DOM tree representation. Then we specify extraction patterns as paths from the root of the DOM tree to the node containing the values to extract. Special languages such as XPath or XQuery support searching and querying elements of a DOM tree.</p>
<p>Below we show a simple HTML Web page and its representation as a HTML DOM tree.</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode html"><code class="sourceCode html"><span id="cb97-1"><a href="scraping.html#cb97-1"></a><span class="kw">&lt;html&gt;</span></span>
<span id="cb97-2"><a href="scraping.html#cb97-2"></a>  <span class="kw">&lt;head&gt;</span></span>
<span id="cb97-3"><a href="scraping.html#cb97-3"></a>    <span class="kw">&lt;title&gt;</span>My Title<span class="kw">&lt;/title&gt;</span></span>
<span id="cb97-4"><a href="scraping.html#cb97-4"></a>  <span class="kw">&lt;/head&gt;</span></span>
<span id="cb97-5"><a href="scraping.html#cb97-5"></a>  <span class="kw">&lt;body&gt;</span></span>
<span id="cb97-6"><a href="scraping.html#cb97-6"></a>    <span class="kw">&lt;a</span><span class="ot"> href=</span><span class="st">&quot;&quot;</span><span class="kw">&gt;</span>My link<span class="kw">&lt;/a&gt;</span></span>
<span id="cb97-7"><a href="scraping.html#cb97-7"></a>    <span class="kw">&lt;h1&gt;</span>My header<span class="kw">&lt;/h1&gt;</span></span>
<span id="cb97-8"><a href="scraping.html#cb97-8"></a>  <span class="kw">&lt;/body&gt;</span></span>
<span id="cb97-9"><a href="scraping.html#cb97-9"></a><span class="kw">&lt;/html&gt;</span></span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:htmlDOM"></span>
<img src="data/WebDataExtraction/HTML_DOM.png" alt="DOM tree representation of the above HTML Web page."  />
<p class="caption">
Figure 4.1: DOM tree representation of the above HTML Web page.
</p>
</div>
<p>The HTML DOM is an Object Model for HTML and it defines:</p>
<ul>
<li>HTML elements as objects.</li>
<li>Properties for all HTML elements.</li>
<li>Methods for all HTML elements.</li>
<li>Events for all HTML elements.</li>
</ul>
<p>Interactive Web pages mostly consist of Javascript code which is executed directly in the Web browser. The HTML DOM is also an API (Programming Interface) for JavaScript that allows it to dynamically:</p>
<ul>
<li>Add/change/remove HTML elements/attributes/events.</li>
<li>Add/change/remove CSS styles.</li>
<li>React to HTML events.</li>
</ul>
</div>
<div id="xpath" class="section level3">
<h3><span class="header-section-number">4.2.2</span> XPath</h3>
<p>One of the main advantage of the adoption of the Document Object Model for Web Content Extraction is the possibility of exploiting the tools for XML languages (and HTML is to all effects a dialect of the XML). In particular, the XML Path Language (XPath) provides with a powerful syntax to succintly address specific elements of an XML document. XPath was also defined by the World Wide Web consortium, as was DOM.</p>
<p>Below we provide an XML example to explain how XPath can be used to address elements of a Web page.</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode html"><code class="sourceCode html"><span id="cb98-1"><a href="scraping.html#cb98-1"></a><span class="kw">&lt;persons&gt;</span></span>
<span id="cb98-2"><a href="scraping.html#cb98-2"></a>  <span class="kw">&lt;person&gt;</span></span>
<span id="cb98-3"><a href="scraping.html#cb98-3"></a>    <span class="kw">&lt;name&gt;</span>John<span class="kw">&lt;/name&gt;</span></span>
<span id="cb98-4"><a href="scraping.html#cb98-4"></a>    <span class="kw">&lt;height</span><span class="ot"> unit=</span><span class="st">”cm”</span><span class="kw">&gt;</span>191<span class="kw">&lt;/height&gt;</span></span>
<span id="cb98-5"><a href="scraping.html#cb98-5"></a>    <span class="kw">&lt;sport&gt;</span>Running<span class="kw">&lt;/sport&gt;</span></span>
<span id="cb98-6"><a href="scraping.html#cb98-6"></a>    <span class="kw">&lt;sport&gt;</span>Cycling<span class="kw">&lt;/sport&gt;</span></span>
<span id="cb98-7"><a href="scraping.html#cb98-7"></a>  <span class="kw">&lt;/person&gt;</span></span>
<span id="cb98-8"><a href="scraping.html#cb98-8"></a>  <span class="kw">&lt;person&gt;</span></span>
<span id="cb98-9"><a href="scraping.html#cb98-9"></a>    <span class="kw">&lt;name&gt;</span>Mandy<span class="kw">&lt;/name&gt;</span></span>
<span id="cb98-10"><a href="scraping.html#cb98-10"></a>    <span class="kw">&lt;height&gt;</span>140<span class="kw">&lt;/height&gt;</span></span>
<span id="cb98-11"><a href="scraping.html#cb98-11"></a>   <span class="kw">&lt;sport&gt;</span>Swimming<span class="kw">&lt;/sport&gt;</span></span>
<span id="cb98-12"><a href="scraping.html#cb98-12"></a>  <span class="kw">&lt;/person&gt;</span></span>
<span id="cb98-13"><a href="scraping.html#cb98-13"></a><span class="kw">&lt;/persons&gt;</span></span></code></pre></div>
<p>There exist two possible ways to use XPath: (A) to identify a single element in the document tree, or (B) to address multiple occurrences of elements. We show some XPath queries against the above XML document:</p>
<ul>
<li><code>/persons/person/name</code> - Extract all elements in the provided path. The result is <code>&lt;name&gt;John&lt;/name&gt;</code> and <code>&lt;name&gt;Mandy&lt;/name&gt;</code>.</li>
<li><code>/persons/person/name/text()</code> - Get contents of all the elements that match the provided path. The result is <code>John</code> and <code>Mandy</code>.</li>
<li><code>//person/height[@unit="cm"]/text()</code> - Extract contents of all <em>height</em> objects that have set attribute <em>unit</em> to <em>cm</em> and have their parent element named as <em>person</em>. Result is <code>191</code>.</li>
<li><code>//sport</code> - Extract all elements that appear at any level of XML and are named <em>sport</em>. The result is <code>&lt;sport&gt;Running&lt;/sport&gt;</code>, <code>&lt;sport&gt;Cycling&lt;/sport&gt;</code> and <code>&lt;sport&gt;Swimming&lt;/sport&gt;</code>.</li>
<li><code>//person[name="Mandy"]/sport/text()</code> - Extract contents of <em>sport</em> objects that are nested directly under <em>person</em> objects which contain a <em>name</em> object with value <em>Mandy</em>. The result is <code>Swimming</code>.</li>
</ul>
<p>The major weakness of XPath is its lack of flexibility: each XPath expression is strictly related to the structure of the Web page. However, this limitation has been partially mitigated with the introduction of relative path expressions. In general, even minor changes to the structure of a Web page might corrupt the correct functioning of an XPath expression defined on a previous version of the page. Still, due to the ease of use, many Web extraction libraries support the use of XPath in to addition of their own extraction API.</p>
<p>Let us consider Web pages generated by a script (e.g. the information about a book in an e-commerce Web site). Now assume that the script undergoes some changes. We can expect that the tree structure of the HTML page generated by that script will change accordingly. To keep the Web data extraction process functional, we should update the expression every time the underlying page generation model changes. Such an operation would require a substantial human effort and would therefore be very costly. To this end, the concept of <em>wrapper robustness</em> was introduced. From the perspective of XPath the idea is to find, among all the XPath expressions capable of extracting the same information from a Web page, the one that is least influenced by potential changes in the structure of the page and such an expression identifies the more robust wrapper. In general, to make the entire Web data extraction process robust, we need tools allowing for measuring document similarity. Such a task can be accomplished by detecting structural variations in the DOM trees associated with the documents. Techniques called tree-matching strategies are a good candidate to detect similarities between two trees <span class="citation">(Tai <a href="#ref-treeMatching" role="doc-biblioref">1979</a>)</span>. The discussion of these techniques is outside the scope of this chapter.</p>
</div>
<div id="modern-web-sites-and-js-frameworks" class="section level3">
<h3><span class="header-section-number">4.2.3</span> Modern Web sites and JS frameworks</h3>
<p>Modern Web sites still use HTML to render their data within Web browsers. Below we show an example of a Web page (left side) and extracted content from it (right side). When all pages follow the same structure, we can easily extract all the data.</p>
<table class="additionalSources">
<tr>
<td>
<center>
<b>e-Commerce Web page - product description</b>
</center>
</td>
<td>
<center>
<b>Extracted data in a structured format (JSON)</b>
</center>
</td>
</tr>
<tr>
<td>
<img width="350pt" src="data/WebDataExtraction/productWebPage.png" />
</td>
<td>
<img width="350pt" src="data/WebDataExtraction/productWebPage_JSON.png" />
</td>
</tr>
</table>
<p>However, Web sites are becoming more dynamic - loading data in the background, not refreshing the entire view, etc. These functionalities require dynamic code to be executed directly on the client, that is, inside the Web browser. The main language that can be interpreted by a Web browser is Javascript. Although best practices instruct the programmers to support non-Javascript browsers, there are many Web pages that malfunction if the browser does not support Javascript. With the advent of Single page application (SPA) Web sites the content does not even partially load as the whole Web page is driven by the Javascript. Popular frameworks that enable SPA development are, for example <a href="https://angular.io/">Angular</a>, <a href="https://vuejs.org/">Vue.js</a> or <a href="https://reactjs.org/">React</a>. Below we show some examples of rendering Web pages when a browser runs with Javascript enabled or disabled:</p>
<table class="additionalSources">
<tr>
<td>
<center>
<b>Javascript enabled</b>
</center>
</td>
<td>
<center>
<b>Javascript disabled</b>
</center>
</td>
</tr>
<tr>
<td>
<img src="data/WebDataExtraction/eUprava_JS.png" />
</td>
<td>
<img src="data/WebDataExtraction/eUprava_noJS.png" />
</td>
</tr>
<tr>
<td>
<img src="data/WebDataExtraction/evem_JS.png" />
</td>
<td>
<img src="data/WebDataExtraction/evem_noJS.png" />
</td>
</tr>
</table>
<p>When we develop a Web extraction system we should first review how the target Web site is built and which frontend technologies are used. Then we can also more efficiently use a library to implement a final Web wrapper to extract the desired data. When we need to execute Javascript, our extraction library needs to implement <em>headless browser</em> functionality. This functionality runs a hidden browser to construct a final HTML content which is then used for further manipulation. Libraries that support such functionality are, for example:</p>
<ul>
<li><a href="https://www.seleniumhq.org/">Selenium</a>,</li>
<li><a href="http://phantomjs.org/">phantomJS</a> and</li>
<li><a href="http://htmlunit.sourceforge.net/">HTMLUnit</a>.</li>
</ul>
<p>Running a headless browser and executing Javascript can be time consuming and prone to errors. So, whenever we can, we should rather use just an HTML parsing library. There exist many of such libraries and we mention just a few:</p>
<ul>
<li><a href="http://htmlcleaner.sourceforge.net/">HTML Cleaner</a>,</li>
<li><a href="http://htmlparser.sourceforge.net/">HTML Parser</a>,</li>
<li><a href="https://jsoup.org/">JSoup</a> (Java) or <a href="https://www.crummy.com/software/BeautifulSoup/">BeautifulSoup</a> (Python),</li>
<li><a href="https://jaunt-api.com/">Jaunt API</a> and</li>
<li><a href="http://hc.apache.org/">HTTP Client</a>.</li>
</ul>
</div>
<div id="crawling-resources-and-policies" class="section level3">
<h3><span class="header-section-number">4.2.4</span> Crawling, resources and policies</h3>
<p>Crawling is a process of automatic navigation through Web pages within defined Web sites. When we deal with continuous retrieval of content from a large amount of Web pages, there are many aspects we need to take care of. For example,</p>
<ol style="list-style-type: lower-alpha">
<li>we need to track which pages were already visited,</li>
<li>we need to decide how to handle HTTP redirects or HTTP error codes in case of a delayed retry,</li>
<li>we must follow the rules written in <em>robots.txt</em> for each domain or should follow general crawling ethics so that we not send too many request to a specific server and</li>
<li>we need to track changes on Web pages to identify approximate change-rate, etc.</li>
</ol>
<p>Generally, a crawler architecture will consist of the following components (Figure <a href="scraping.html#fig:crawlerArchitecture">4.2</a>):</p>
<ul>
<li>HTTP downloader and renderer: To retrieve and render a web page.</li>
<li>Data extractor: Minimal functionalities to extract images and hyperlinks.</li>
<li>Duplicate detector: To detect already parsed pages.</li>
<li>URL frontier: A list of URLs waiting to be parsed.</li>
<li>Datastore: To store the data and additional metadata used by the crawler.</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:crawlerArchitecture"></span>
<img src="data/WebDataExtraction/crawler.png" alt="Web crawler architecture."  />
<p class="caption">
Figure 4.2: Web crawler architecture.
</p>
</div>
<p>As we already mentioned before, we need to understand all the specifics how Web pages are built and generated. To make sure that we correctly gather all the needed content placed into the DOM by Javascript, we should use headless browsers. Google’s crawler Googlebot implements this as a two-step process or expects to retrieve dynamically built web page from an HTTP server. A session on crawling modern web sites built using JS frameworks, link parsing and image indexing was a part of Google IO 2018 and we recommend it to get an impression of problems that we can encounter:</p>
<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/PFwUbgvpdaQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</center>
<p>A crawler needs to identify links, which can be encoded in several different ways. They can be explicilty given within <em>href</em> attributes, as <em>onclick</em> Javascript events (e.g. <em>location.href</em> or <em>document.location</em>), etc. Similarly, images can be generated in different formats, shown dynamically, etc. While in some circumstances it might be better to implement a custom crawler, a crawler package or suite is typically a better choice. Here are two examples:</p>
<ul>
<li><a href="https://nutch.apache.org/">Apache Nutch</a>,</li>
<li><a href="https://scrapy.org/">Scrapy</a>.</li>
</ul>
<p>The Web consists also of other files that web pages point to, for example PDF files, Word/OpenOffice documents, Excel spreadsheets, presentations, etc. They may also include some relevant information. We recommend the following tools for parsing such content:</p>
<ul>
<li><a href="https://tika.apache.org/">Apache Tika</a> toolkit detects and extracts metadata and text from over a thousand different file types (such as PPT, XLS, and PDF). All of these file types can be parsed through a single interface, making Tika useful for search engine indexing, content analysis, translation, and much more.</li>
<li><a href="https://poi.apache.org/">Apache Poi</a> focus on manipulating various file formats based upon the Office Open XML standards (OOXML) and Microsoft’s OLE 2 Compound Document format (OLE2). In short, you can read and write MS Excel files using Java.</li>
<li><a href="https://pdfbox.apache.org/">Apache PDFBox</a> library is an open source Java tool for working with PDF documents. This project allows creation of new PDF documents, manipulation of existing documents and the ability to extract content from documents. It also includes several command-line utilities.</li>
</ul>
</div>
</div>
<div id="further-reading-and-references-3" class="section level2">
<h2><span class="header-section-number">4.3</span> Further reading and references</h2>
<ul>
<li><a href="https://www.apress.com/gp/book/9781484235812">Practical Web Scraping for Data Science, Best Practices and Examples with Python (2018), Seppe vanden Broucke and Bart Baesens.</a></li>
<li><a href="https://www.amazon.de/Web-Scraping-Python-Ryan-Mitchell/dp/1491910291">Web Scraping with Python (2015), Ryan Mitchell</a></li>
<li><a href="https://www.amazon.com/Web-Data-Mining-Data-Centric-Applications/dp/3642194591">Web Data Mining: Exploring Hyperlinks, Contents, and Usage Data. 2nd ed. (2011), Bing Liu</a></li>
<li><a href="https://www.w3schools.com/xml/xpath_intro.asp">XPath W3schools tutorial</a></li>
</ul>
</div>
<div id="learning-outcomes-3" class="section level2">
<h2><span class="header-section-number">4.4</span> Learning outcomes</h2>
<p>Data science students should work towards obtaining the knowledge and the skills that enable them to:</p>
<ul>
<li>Understand the architecture and different technologies used in the World Wide Web.</li>
<li>Use or build a standalone Web crawler to gather data from the Web.</li>
<li>Identify and automatically extract the Web page content of interest.</li>
</ul>
</div>
<div id="practice-problems-3" class="section level2">
<h2><span class="header-section-number">4.5</span> Practice problems</h2>
<ol style="list-style-type: decimal">
<li>Explore the Web and find some dynamic Web sites. Inspect the structure of a few Web pages with your favorite browser and try to load the same Web pages with Javascript disabled.</li>
<li>Implement and run a crawler that will target <a href="https://fri.uni-lj.si/sl/o-fakulteti/osebje" class="uri">https://fri.uni-lj.si/sl/o-fakulteti/osebje</a> and extract the following information about every employee: name, email, phone number, title/job position and the number of courses they teach and number of projects they have listed. Save the data in CSV format.</li>
<li>An example project: Recently, <a href="http://gov.si">gov.si</a> Web site has been launched. Build a crawler that will retrieve semi-structured data from the site only. Also, you need to obey crawler ethics, take into account <em>robots.txt</em>, etc. Store rendered HTML data and also extracted data in a database.</li>
</ol>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-aggarwal2012">
<p>Aggarwal, Charu C, and ChengXiang Zhai. 2012. <em>Mining Text Data</em>. Springer Science &amp; Business Media.</p>
</div>
<div id="ref-manning2008">
<p>Christopher, D Manning, Raghavan Prabhakar, and Schacetzel Hinrich. 2008. “Introduction to Information Retrieval.” <em>An Introduction to Information Retrieval</em> 151 (177): 5.</p>
</div>
<div id="ref-deitel2011">
<p>Deitel, Paul, Harvey Deitel, and Abbey Deitel. 2011. <em>Internet &amp; World Wide Web: How to Program</em>. 5th ed. Pearson. <a href="https://www.amazon.com/Internet-World-Wide-Web-Program/dp/0132151006">https://www.amazon.com/Internet-World-Wide-Web-Program/dp/0132151006</a>.</p>
</div>
<div id="ref-ferrara2014">
<p>Ferrara, Emilio, Pasquale De Meo, Giacomo Fiumara, and Robert Baumgartner. 2014. “Web Data Extraction, Applications and Techniques: A Survey.” <em>Knowledge-Based Systems</em> 70: 301–23.</p>
</div>
<div id="ref-InternetWorldStats">
<p>Internet World Stats. 2017. “Usage and Population Statistics.” 2017. <a href="http://www.internetworldstats.com/stats.htm">http://www.internetworldstats.com/stats.htm</a>.</p>
</div>
<div id="ref-kushmerick1997">
<p>Kushmerick, Nicholas, Daniel S Weld, and Robert Doorenbos. 1997. “Wrapper Induction for Information Extraction.”</p>
</div>
<div id="ref-liu2011">
<p>Liu, Bing. 2011. <em>Web Data Mining: Exploring Hyperlinks, Contents, and Usage Data</em>. 2nd ed. Springer Publishing Company, Incorporated.</p>
</div>
<div id="ref-treeMatching">
<p>Tai, Kuo-Chung. 1979. “The Tree-to-Tree Correction Problem.” <em>J. ACM</em> 26 (3): 422–33. <a href="https://doi.org/10.1145/322139.322143">https://doi.org/10.1145/322139.322143</a>.</p>
</div>
</div>
<script type="application/json" class="js-hypothesis-config">
	{
	  "openSidebar": false,
	  "showHighlights": "whenSidebarOpen",
	  "enableShareLinks": false
	}
</script>
<script src="https://hypothes.is/embed.js" async></script>
            </section>

          </div>
        </div>
      </div>
<a href="reproducibility.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="summarizing-data-basics.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
